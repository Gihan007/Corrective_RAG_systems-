{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482e23c5",
   "metadata": {},
   "source": [
    "LLM and Needed Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\" , google_api_key=\"API\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.7 , openai_api_key=\"API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365e69c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the island nation where the oceans sing,  \n",
      "Stands a leader known as Ranil Wickramasinghe,  \n",
      "With wisdom carved from history's page,  \n",
      "A statesman walking through a turbulent age.  \n",
      "\n",
      "Born under the Lankan sun's embrace,  \n",
      "He carries forward a storied place,  \n",
      "With dreams of unity and lasting peace,  \n",
      "He strives for the island's woes to cease.  \n",
      "\n",
      "From bustling Colombo to the rural fields,  \n",
      "His vision for progress never yields,  \n",
      "Balancing tradition with modern grace,  \n",
      "Seeking to uplift every face.  \n",
      "\n",
      "Through trials that test the strongest will,  \n",
      "He navigates with a statesman's skill,  \n",
      "In the halls of power, his voice resounds,  \n",
      "Guiding the nation through ups and downs.  \n",
      "\n",
      "A tapestry woven with diverse threads,  \n",
      "A future of hope, where history treads,  \n",
      "Ranil dreams of a brighter morn,  \n",
      "For the land where he was born.  \n",
      "\n",
      "With every challenge that time may bring,  \n",
      "His steadfast heart continues to sing,  \n",
      "Of peace, prosperity, and dreams anew,  \n",
      "In the heart of Lanka, where skies are blue.  \n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Write a poem about ranil wickramasinghe\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd53107",
   "metadata": {},
   "source": [
    "Build Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b7049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c4d05",
   "metadata": {},
   "source": [
    "hugging face embesdding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ca5be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Temp\\ipykernel_48812\\2653006643.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  huggingface_embeddings = HuggingFaceEmbeddings()\n",
      "C:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Temp\\ipykernel_48812\\2653006643.py:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  huggingface_embeddings = HuggingFaceEmbeddings()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[1;32m----> 2\u001b[0m huggingface_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:223\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     emit_warning()\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:92\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer(\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[0;32m     94\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:191\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token)\u001b[0m\n\u001b[0;32m    188\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(model_name_or_path, token, cache_folder\u001b[38;5;241m=\u001b[39mcache_folder, revision\u001b[38;5;241m=\u001b[39mrevision):\n\u001b[1;32m--> 191\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    200\u001b[0m         model_name_or_path,\n\u001b[0;32m    201\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    205\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1217\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code)\u001b[0m\n\u001b[0;32m   1207\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config_name \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m   1209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_bert_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_roberta_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_xlnet_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1216\u001b[0m ]:\n\u001b[1;32m-> 1217\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m \u001b[43mload_file_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config_path) \u001b[38;5;28;01mas\u001b[39;00m fIn:\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\util.py:532\u001b[0m, in \u001b[0;36mload_file_path\u001b[1;34m(model_name_or_path, filename, token, cache_folder, revision)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# If file is remote\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence-transformers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1008\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    990\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1006\u001b[0m     )\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1071\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[1;32m-> 1071\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1533\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1532\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1533\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1536\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1537\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1538\u001b[0m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1450\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1447\u001b[0m hf_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1450\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 286\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    287\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    288\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    289\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, retry_on_exceptions\u001b[38;5;241m=\u001b[39m(), retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,))\n\u001b[0;32m    310\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:310\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    463\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    467\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 468\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:463\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "huggingface_embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a96a71",
   "metadata": {},
   "source": [
    "store in a Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc9d0983",
   "metadata": {},
   "outputs": [
    {
     "ename": "GoogleGenerativeAIError",
     "evalue": "Error embedding content: 400 * BatchEmbedContentsRequest.model: unexpected model name format\n* BatchEmbedContentsRequest.requests[0].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[1].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[2].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[3].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[4].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[5].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[6].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[7].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[8].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[9].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[10].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[11].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[12].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[13].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[14].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[15].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[16].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[17].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[18].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[19].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[20].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[21].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[22].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[23].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[24].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[25].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[26].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[27].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[28].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[29].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[30].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[31].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[32].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[33].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[34].model: unexpected model name format\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\embeddings.py:227\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[1;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_embed_contents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBatchEmbedContentsRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:1392\u001b[0m, in \u001b[0;36mGenerativeServiceClient.batch_embed_contents\u001b[1;34m(self, request, model, requests, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 * BatchEmbedContentsRequest.model: unexpected model name format\n* BatchEmbedContentsRequest.requests[0].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[1].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[2].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[3].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[4].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[5].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[6].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[7].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[8].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[9].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[10].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[11].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[12].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[13].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[14].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[15].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[16].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[17].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[18].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[19].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[20].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[21].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[22].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[23].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[24].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[25].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[26].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[27].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[28].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[29].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[30].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[31].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[32].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[33].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[34].model: unexpected model name format\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGoogleGenerativeAIError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Add to vectorDB\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrag-chroma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    885\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    886\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m    888\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    889\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    890\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    891\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    892\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    893\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory,\n\u001b[0;32m    894\u001b[0m     client_settings\u001b[38;5;241m=\u001b[39mclient_settings,\n\u001b[0;32m    895\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m    896\u001b[0m     collection_metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    898\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:843\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    838\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    839\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    840\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    841\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    842\u001b[0m     ):\n\u001b[1;32m--> 843\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    849\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_google_genai\\embeddings.py:231\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[1;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[0;32m    227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbatch_embed_contents(\n\u001b[0;32m    228\u001b[0m             BatchEmbedContentsRequest(requests\u001b[38;5;241m=\u001b[39mrequests, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    229\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GoogleGenerativeAIError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError embedding content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;28mlist\u001b[39m(e\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39membeddings])\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[1;31mGoogleGenerativeAIError\u001b[0m: Error embedding content: 400 * BatchEmbedContentsRequest.model: unexpected model name format\n* BatchEmbedContentsRequest.requests[0].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[1].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[2].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[3].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[4].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[5].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[6].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[7].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[8].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[9].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[10].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[11].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[12].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[13].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[14].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[15].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[16].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[17].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[18].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[19].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[20].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[21].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[22].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[23].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[24].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[25].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[26].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[27].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[28].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[29].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[30].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[31].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[32].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[33].model: unexpected model name format\n* BatchEmbedContentsRequest.requests[34].model: unexpected model name format\n"
     ]
    }
   ],
   "source": [
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3dc19",
   "metadata": {},
   "source": [
    "Lets Create a RAG Chain Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550d6c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---PROMPT--- input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "print(f\"---PROMPT--- {prompt}\")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6221b0",
   "metadata": {},
   "source": [
    "RAG chain Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c441ec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent memory in LLM-powered autonomous systems consists of two types: short-term memory and long-term memory. Short-term memory utilizes in-context learning, allowing the model to process information during a session. Long-term memory enables the agent to retain and recall information over extended periods, often using an external vector store for fast retrieval.\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "question = \"tell me about agent memory.\"\n",
    "generation = rag_chain.invoke({\"context\": doc_splits, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780482d2",
   "metadata": {},
   "source": [
    "Now lets create grade document class which is accountable for check if user quire is relevent to the document or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6053b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d3dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c707c8f",
   "metadata": {},
   "source": [
    "Testing , if working or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b0b52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Temp\\ipykernel_41820\\2925432907.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "question = \"tell me about the agent memory.\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c672fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "question = \"tell me about the Tajmahal.\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e2191",
   "metadata": {},
   "source": [
    "### Let's Create Question Re-Writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db4ba4",
   "metadata": {},
   "source": [
    "Re Writing the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19475888",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question Re-writer\n",
    "# Prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "     \n",
    "     \n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac729522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the history and significance of the Taj Mahal?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_rewriter.invoke({\"question\": question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1a521",
   "metadata": {},
   "source": [
    "### Corrective Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d5ed7",
   "metadata": {},
   "source": [
    "lets create functions that needed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78b9f6",
   "metadata": {},
   "source": [
    "Agent State Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0aa7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]\n",
    "\n",
    "workflow= StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed5783",
   "metadata": {},
   "source": [
    "retrive agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2383ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically here we try to get most similar documents to the question\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a4068",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e83f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n"
     ]
    }
   ],
   "source": [
    "x = retrieve({\"question\": \"do u knwo about bla bla black ships?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ab0921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: documents | Value: [Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Attack\\nType\\nDescription\\n\\n\\n\\n\\nToken manipulation\\nBlack-box\\nAlter a small fraction of tokens in the text input such that it triggers model failure but still remain its original semantic meanings.\\n\\n\\nGradient based attack\\nWhite-box\\nRely on gradient signals to learn an effective attack.\\n\\n\\nJailbreak prompting\\nBlack-box\\nOften heuristic based prompting to “jailbreak” built-in model safety.\\n\\n\\nHuman red-teaming\\nBlack-box\\nHuman attacks the model, with or without assist from other models.\\n\\n\\nModel red-teaming\\nBlack-box\\nModel attacks the model, where the attacker model can be fine-tuned.'), Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Black-box attacks assume that attackers only have access to an API-like service where they provide input $\\\\mathbf{x}$ and get back sample $\\\\mathbf{y}$, without knowing further information about the model.\\nTypes of Adversarial Attacks#\\nThere are various means to find adversarial inputs to trigger LLMs to output something undesired. We present five approaches here.'), Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='White-box attacks often lead to nonsensical adversarial prompts and thus they can be detected by examining perplexity. Of course, a white-box attack can directly bypass this by explicitly optimizing for lower perplexity, such as UAT-LM, a variation of UAT. However, there is a tradeoff and it can lead to lower attack success rate.'), Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Given an input $\\\\mathbf{x}$ and a generative model $p(.)$, we have the model output a sample $\\\\mathbf{y} \\\\sim p(.\\\\vert\\\\mathbf{x})$ . An adversarial attack would identify such $p(\\\\mathbf{x})$ that $\\\\mathbf{y}$ would violate the built-in safe behavior of the model $p$; E.g. output unsafe content on illegal topics, leak private information or model training data. For generative tasks, it is not easy to judge the success of an attack, which demands a super high-quality classifier to judge whether $\\\\mathbf{y}$ is unsafe or human review.\\nWhite-box vs Black-box#\\nWhite-box attacks assume that attackers have full access to the model weights, architecture and training pipeline, such that attackers can obtain gradient signals. We don’t assume attackers have access to the full training data. This is only possible for open-sourced models.')]\n",
      "Key: question | Value: do u knwo about bla bla black ships?\n"
     ]
    }
   ],
   "source": [
    "for key, value in x.items():\n",
    "    print(f\"Key: {key} | Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8837d",
   "metadata": {},
   "source": [
    "grade Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e931748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---CHECKING DOCUMENT RELEVANT IS TO QUESTION OR NOT---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    \n",
    "    web_search = \"No\"\n",
    "    \n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        ) \n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e8ff5",
   "metadata": {},
   "source": [
    "generate Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390b597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---GENERATE---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a674b19",
   "metadata": {},
   "source": [
    "Transform the querry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0497bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec837c0b",
   "metadata": {},
   "source": [
    "### Web Crawling we gonna perform using Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d99269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Temp\\ipykernel_41820\\1927559686.py:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search_tool = TavilySearchResults(k=3 , tavily_api_key=\"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\")\n"
     ]
    }
   ],
   "source": [
    "### Search\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3 , tavily_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a657ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavily API key is working!\n",
      "Sample result: HTTPError('432 Client Error:  for url: https://api.tavily.com/search')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try a simple test query\n",
    "try:\n",
    "    results = web_search_tool.run(\"Latest news on AI\")\n",
    "    print(\"Tavily API key is working!\")\n",
    "    print(\"Sample result:\", results[:500])  # Print first 500 chars\n",
    "except Exception as e:\n",
    "    print(\"Error: Tavily API key is not working.\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "321e0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call successful!\n",
      "Result preview: HTTPError('432 Client Error:  for url: https://api.tavily.com/search')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    # Simple query with minimal params\n",
    "    results = web_search_tool.run(\"Hello world\")\n",
    "    print(\"API call successful!\")\n",
    "    print(\"Result preview:\", results[:500])\n",
    "except Exception as e:\n",
    "    print(\"API call failed!\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5437fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.schema import Document\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "\n",
    "    # Handle if docs is a list of strings or a single string\n",
    "    if isinstance(docs, list):\n",
    "        web_results = \"\\n\".join(docs)\n",
    "    else:\n",
    "        web_results = str(docs)\n",
    "\n",
    "    # Wrap in Document\n",
    "    web_results_doc = Document(page_content=web_results)\n",
    "    documents.append(web_results_doc)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d98898",
   "metadata": {},
   "source": [
    "getting error in Tavily serch API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ec3686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---WEB SEARCH---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'documents': ['hey ',\n",
       "  Document(metadata={}, page_content=\"HTTPError('432 Client Error:  for url: https://api.tavily.com/search')\")],\n",
       " 'question': 'tell me about the Tajmahal.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search({\"question\": \"tell me about the Tajmahal.\" , \"documents\": [\"hey \"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa6b06",
   "metadata": {},
   "source": [
    "Deciding Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52718175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf47efba",
   "metadata": {},
   "source": [
    "Let's create a skeleton of code then will create the function accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f18d2205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bb7b56ba30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the nodes\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "workflow.add_node(\"web_search_node\", web_search)  # web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6011b7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bb7b56ba30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "workflow.add_conditional_edges(\"grade_documents\", decide_to_generate, {\"transform_query\": \"transform_query\",\"generate\": \"generate\",}),\n",
    "\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75f6fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e324c7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Display the graph\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m display(Image(\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\runnables\\graph.py:695\u001b[0m, in \u001b[0;36mGraph.draw_mermaid_png\u001b[1;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[0;32m    689\u001b[0m mermaid_syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_mermaid(\n\u001b[0;32m    690\u001b[0m     curve_style\u001b[38;5;241m=\u001b[39mcurve_style,\n\u001b[0;32m    691\u001b[0m     node_colors\u001b[38;5;241m=\u001b[39mnode_colors,\n\u001b[0;32m    692\u001b[0m     wrap_label_n_words\u001b[38;5;241m=\u001b[39mwrap_label_n_words,\n\u001b[0;32m    693\u001b[0m     frontmatter_config\u001b[38;5;241m=\u001b[39mfrontmatter_config,\n\u001b[0;32m    694\u001b[0m )\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:294\u001b[0m, in \u001b[0;36mdraw_mermaid_png\u001b[1;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[0;32m    288\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    289\u001b[0m         _render_mermaid_using_pyppeteer(\n\u001b[0;32m    290\u001b[0m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[0;32m    291\u001b[0m         )\n\u001b[0;32m    292\u001b[0m     )\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m draw_method \u001b[38;5;241m==\u001b[39m MermaidDrawMethod\u001b[38;5;241m.\u001b[39mAPI:\n\u001b[1;32m--> 294\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "File \u001b[1;32mc:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:451\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[1;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m     ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mRequestException, requests\u001b[38;5;241m.\u001b[39mTimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the graph\n",
    "from IPython.display import Image, display \n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bed84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Temp\\ipykernel_41820\\83072921.py:8: UserWarning: Glyph 9 (\t) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(\"graph.png\", bbox_inches=\"tight\", dpi=300)\n",
      "c:\\Users\\GIHAN LAKMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 9 (\t) missing from font(s) DejaVu Sans Mono.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mermaid_code = app.get_graph(xray=True).draw_mermaid()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.text(0, 0.5, mermaid_code, fontsize=8, family=\"monospace\", va=\"center\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"graph.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba978e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\"question\": \"tell me about the agent memory.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d4ba1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---CHECKING DOCUMENT RELEVANT IS TO QUESTION OR NOT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "('In an LLM-powered autonomous agent system, memory is divided into short-term '\n",
      " 'and long-term components. Short-term memory involves in-context learning and '\n",
      " 'prompt engineering, while long-term memory allows the agent to retain and '\n",
      " 'recall information over extended periods by using an external vector store '\n",
      " 'and fast retrieval. This memory structure enables the agent to learn from '\n",
      " 'past experiences and adapt its future actions accordingly.')\n"
     ]
    }
   ],
   "source": [
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1abe688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\"question\": \"tell me about the taj mahal.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ecdb43",
   "metadata": {},
   "source": [
    "tavily serch key issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a365d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---CHECKING DOCUMENT RELEVANT IS TO QUESTION OR NOT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---TRANSFORM QUERY---\n",
      "\"Node 'transform_query':\"\n",
      "'\\n---\\n'\n",
      "---WEB SEARCH---\n",
      "\"Node 'web_search_node':\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "\"I don't know.\"\n"
     ]
    }
   ],
   "source": [
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76130e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
